{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"REF: https://github.com/GoogleCloudPlatform/df-ml-anomaly-detection/blob/master/README.md\">Reference1<a/>  <br>\n",
    "<a href=\"https://faker.readthedocs.io/en/master/\">Reference2<a/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with beam.Pipeline() as pipeline:\n",
    "    total_unique_elements = (\n",
    "        pipeline\n",
    "        | 'Create produce' >> beam.Create(\n",
    "            [{\"name\":\"idris\",\"salary\":500,\"test\":5}, {\"name\":\"idris\",\"salary\":500,\"test\":5}, {\"name\":\"idris\",\"salary\":500,\"test\":6}, {\"name\":\"ade\",\"salary\":900,\"test\":5}])\n",
    "        | 'row' >> beam.Map(lambda row: beam.Row(name=row['name'],salary=row[\"salary\"],test=row[\"test\"]))\n",
    "        | 'Pair with 1' >> beam.GroupBy(\"name\")\\\n",
    "        .aggregate_field(\n",
    "            \"name\", count_distint, \"count\"\n",
    "        ).aggregate_field(\n",
    "            \"test\", beam.Distinct(), \"test\"\n",
    "        )\n",
    "        #     \"name\", beam.combiners.Iterable(), \"count\").aggregate_field(\n",
    "        #       \"salary\", beam.combiners.MeanCombineFn(), \"avg_salary\").aggregate_field(\n",
    "        #         \"salary\", sum, \"total_salary\")\n",
    "        | beam.Map(print)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = beam.Pipeline()\n",
    "raw_events = (\n",
    "    pipeline\n",
    "    | 'Read from PubSub' >> beam.Create(['{\"foo\": \"bar\"}' for _ in range(10)])\n",
    "    | 'Parse events' >> beam.ParDo(EventParser()).with_outputs('valid', 'invalid')\n",
    ")\n",
    "\n",
    "(raw_events.invalid \n",
    " |'Log invalid events' >> beam.io.fileio.WriteToFiles(\"data/invalid_events\",shards=2,max_writers_per_bundle=2))\n",
    "\n",
    "(raw_events.valid \n",
    " | \"time\" >> beam.Map(lambda x: beam.window.TimestampedValue(x, time.time()))\n",
    " | 'Add timestamps' >> beam.ParDo(AddTimestamp())\n",
    " | \"add key\" >> beam.Map(print))\n",
    "\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "import random\n",
    "import apache_beam as beam\n",
    "from utils.custom import NetworkPool, UserObject, JsonEvent\n",
    "from apache_beam.transforms.periodicsequence import PeriodicImpulse\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "        \n",
    "def to_json(event):\n",
    "    return json.dumps(event).encode('utf-8')        \n",
    "\n",
    "class AgggregateEvent(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        \n",
    "        network = self.network_pool.get_network()\n",
    "        user = self.user_obj.get_user()\n",
    "        num_events = random.randint(5, self.max_events_per_session)\n",
    "        for _ in range(num_events):\n",
    "            event = JsonEvent.generate(user, network)\n",
    "            yield event\n",
    "                        \n",
    "def run(args, beam_args):\n",
    "    options = PipelineOptions(beam_args, save_main_session=True, streaming=True)\n",
    "    pipeline = beam.Pipeline(options=options)\n",
    "    (\n",
    "        pipeline\n",
    "        | \"Trigger\" >> PeriodicImpulse(start_timestamp=time.time(), fire_interval=(60/args.qps))\n",
    "        | \"Generate Events\" >> beam.ParDo(EventGenerator())\n",
    "        | \"JSONIFY\" >> beam.Map(to_json)\n",
    "        | \"Write to PubSub\" >> beam.io.WriteToPubSub(args.topic)\n",
    "    )\n",
    "    return pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data\n",
    "\n",
    "{\n",
    "  \"subscriberId\":(11111111111,99999999999)\n",
    "  \"srcIP\": \"ipv4\"\n",
    "  \"dstIP\": \"subnet\"\n",
    "  \"srcPort\": (1000,5000)\n",
    "  \"dstPort\": (1000,5000)\n",
    "  \"txBytes\": (0,1000000000)\n",
    "  \"rxBytes\": (0,1000000000)\n",
    "  \"tcpFlag\": (0,65)\n",
    "  \"startTime\": \"timestamp\"\n",
    "  \"endTime\": \"timestamp\"\n",
    "  \"protocolName\": \"tcp|udp|http\"\n",
    "  \"protocolNumber\": (0,255)\n",
    "  \"geoCountry\": \"country\"\n",
    "  \"geoCity\": \"city\"\n",
    "  \"latitude\": (0,90)\n",
    "  \"longitude\": (0,180)\n",
    "}\n",
    "\n",
    "# transformed data\n",
    "{\n",
    "  \"transaction_time\": \"2019-10-27 23:22:17.848000\",\n",
    "  \"subscriber_id\": \"100\",\n",
    "  \"dst_subnet\": \"12.0.1.2/22\",\n",
    "  \"number_of_unique_ips\": \"1\",\n",
    "  \"number_of_unique_ports\": \"1\",\n",
    "  \"number_of_records\": \"2\",\n",
    "  \"max_tx_bytes\": \"15\",\n",
    "  \"min_tx_bytes\": \"10\",\n",
    "  \"avg_tx_bytes\": \"12.5\",\n",
    "  \"max_rx_bytes\": \"40\",\n",
    "  \"min_rx_bytes\": \"40\",\n",
    "  \"avg_rx_bytes\": \"40.0\",\n",
    "  \"max_duration\": \"100\",\n",
    "  \"min_duration\": \"9\",\n",
    "  \"avg_duration\": \"54.5\"\n",
    "}\n",
    "\n",
    "# model features\n",
    "{  \"number_of_records\": \"2\",\n",
    "  \"max_tx_bytes\": \"15\",\n",
    "  \"min_tx_bytes\": \"10\",\n",
    "  \"avg_tx_bytes\": \"12.5\",\n",
    "  \"max_rx_bytes\": \"40\",\n",
    "  \"min_rx_bytes\": \"40\",\n",
    "  \"avg_rx_bytes\": \"40.0\",\n",
    "  \"max_duration\": \"100\",\n",
    "  \"min_duration\": \"9\",\n",
    "  \"avg_duration\": \"54.5\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python3 pipeline.py --streaming --project \"electric-armor-395015\" --topic \"projects/electric-armor-395015/topics/test\" --qps 10 --runner \"DataflowRunner\" --region europe-west2 temp_location gs://my_terraform_state_bucket/temp staging_location gs://my_terraform_state_bucket/staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gcloud pubsub subscriptions pull test-sub --auto-ack --limit 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
