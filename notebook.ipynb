{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"REF: https://github.com/GoogleCloudPlatform/df-ml-anomaly-detection/blob/master/README.md\">Reference1<a/>  <br>\n",
    "<a href=\"https://faker.readthedocs.io/en/master/\">Reference2<a/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with beam.Pipeline() as pipeline:\n",
    "    total_unique_elements = (\n",
    "        pipeline\n",
    "        | 'Create produce' >> beam.Create(\n",
    "            [{\"name\":\"idris\",\"salary\":500,\"test\":5}, {\"name\":\"idris\",\"salary\":500,\"test\":5}, {\"name\":\"idris\",\"salary\":500,\"test\":6}, {\"name\":\"ade\",\"salary\":900,\"test\":5}])\n",
    "        | 'row' >> beam.Map(lambda row: beam.Row(name=row['name'],salary=row[\"salary\"],test=row[\"test\"]))\n",
    "        | 'Pair with 1' >> beam.GroupBy(\"name\", \"salary\")\\\n",
    "        .aggregate_field(\n",
    "            \"name\", UniqueCombine(), \"count\"\n",
    "        ).aggregate_field(\n",
    "            \"test\", UniqueCombine(), \"test\"\n",
    "        ).aggregate_field(\n",
    "            \"name\", pick, \"avg_salary\"\n",
    "        )\n",
    "        )\n",
    "    total_unique_elements | 'Add timestamp' >> beam.ParDo(AddTimestamp()).with_output_types(r) | beam.Map(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with beam.Pipeline() as pipeline:\n",
    "    total_unique_elements = (\n",
    "        pipeline\n",
    "        | 'Create produce' >> beam.Create(\n",
    "            [{\"name\":\"idris\",\"salary\":500,\"test\":5}, {\"name\":\"idris\",\"salary\":500,\"test\":5}, {\"name\":\"idris\",\"salary\":500,\"test\":6}, {\"name\":\"ade\",\"salary\":900,\"test\":5}])\n",
    "        | 'row' >> beam.Map(lambda row: beam.Row(name=row['name'],salary=row[\"salary\"],test=row[\"test\"]))\n",
    "        )\n",
    "    total_unique_elements | 'Add timestamp' >> beam.ParDo(AddTimestamp()) | beam.Map(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipaddress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "\n",
    "faker = Faker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskString = \"255.255.252.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268, 268, 3.2353036052947104, 83.09703156518458)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "anomaly = False\n",
    "start_time = datetime.now()\n",
    "time_diff = random.uniform(0, 10)\n",
    "end_time = start_time + timedelta(seconds=time_diff)\n",
    "random_byte = random.uniform(10, 100)\n",
    "normalized_byte = int(min((random_byte * time_diff), 5000))\n",
    "a = normalized_byte if not anomaly else normalized_byte * 10\n",
    "a , normalized_byte, time_diff, random_byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = [5 if not anomaly else 5 * 10]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipaddress\n",
    "\n",
    "def ip_to_cidr(ip, subnet_mask):\n",
    "    # Parse the IP address and subnet mask\n",
    "    ip_network = ipaddress.IPv4Network(f\"{ip}/{subnet_mask}\", strict=False)\n",
    "    \n",
    "    # Get the CIDR notation\n",
    "    cidr_notation = str(ip_network)\n",
    "    \n",
    "    return cidr_notation\n",
    "\n",
    "# Example usage\n",
    "ip = \"192.168.1.10\"\n",
    "subnet_mask = \"255.255.255.0\"\n",
    "\n",
    "cidr = ip_to_cidr(ip, subnet_mask)\n",
    "print(cidr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = ipaddress.IPv4Address(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data\n",
    "\n",
    "{\n",
    "  \"subscriberId\":(11111111111,99999999999)\n",
    "  \"srcIP\": \"ipv4\"\n",
    "  \"dstIP\": \"subnet\"\n",
    "  \"srcPort\": (1000,5000)\n",
    "  \"dstPort\": (1000,5000)\n",
    "  \"txBytes\": (0,1000000000)\n",
    "  \"rxBytes\": (0,1000000000)\n",
    "  \"tcpFlag\": (0,65)\n",
    "  \"startTime\": \"timestamp\"\n",
    "  \"endTime\": \"timestamp\"\n",
    "  \"protocolName\": \"tcp|udp|http\"\n",
    "  \"protocolNumber\": (0,255)\n",
    "  \"geoCountry\": \"country\"\n",
    "  \"geoCity\": \"city\"\n",
    "  \"latitude\": (0,90)\n",
    "  \"longitude\": (0,180)\n",
    "}\n",
    "\n",
    "# transformed data\n",
    "{\n",
    "  \"transaction_time\": \"2019-10-27 23:22:17.848000\",\n",
    "  \"subscriber_id\": \"100\",\n",
    "  \"dst_subnet\": \"12.0.1.2/22\",\n",
    "  \"number_of_unique_ips\": \"1\",\n",
    "  \"number_of_unique_ports\": \"1\",\n",
    "  \"number_of_records\": \"2\",\n",
    "  \"max_tx_bytes\": \"15\",\n",
    "  \"min_tx_bytes\": \"10\",\n",
    "  \"avg_tx_bytes\": \"12.5\",\n",
    "  \"max_rx_bytes\": \"40\",\n",
    "  \"min_rx_bytes\": \"40\",\n",
    "  \"avg_rx_bytes\": \"40.0\",\n",
    "  \"max_duration\": \"100\",\n",
    "  \"min_duration\": \"9\",\n",
    "  \"avg_duration\": \"54.5\"\n",
    "}\n",
    "\n",
    "# model features\n",
    "{  \"number_of_records\": \"2\",\n",
    "  \"max_tx_bytes\": \"15\",\n",
    "  \"min_tx_bytes\": \"10\",\n",
    "  \"avg_tx_bytes\": \"12.5\",\n",
    "  \"max_rx_bytes\": \"40\",\n",
    "  \"min_rx_bytes\": \"40\",\n",
    "  \"avg_rx_bytes\": \"40.0\",\n",
    "  \"max_duration\": \"100\",\n",
    "  \"min_duration\": \"9\",\n",
    "  \"avg_duration\": \"54.5\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python3 pipeline.py --streaming --project \"electric-armor-395015\" --topic \"projects/electric-armor-395015/topics/test\" --qps 10 --runner \"DataflowRunner\" --region europe-west2 temp_location gs://my_terraform_state_bucket/temp staging_location gs://my_terraform_state_bucket/staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gcloud pubsub subscriptions pull test-sub --auto-ack --limit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n",
      "20\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "30\n",
      "32\n",
      "34\n",
      "36\n",
      "38\n",
      "40\n",
      "42\n",
      "44\n",
      "46\n",
      "48\n",
      "50\n",
      "52\n",
      "54\n",
      "56\n",
      "58\n",
      "60\n",
      "62\n",
      "64\n",
      "66\n",
      "68\n",
      "70\n",
      "72\n",
      "74\n",
      "76\n",
      "78\n",
      "80\n",
      "82\n",
      "84\n",
      "86\n",
      "88\n",
      "90\n",
      "92\n",
      "94\n",
      "96\n",
      "98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fa1fef3ca90>"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "beam_args, args = parser.parse_known_args()\n",
    "\n",
    "options = PipelineOptions(args)\n",
    "# Define the PubSub subscription and GCS bucket\n",
    "\n",
    "bucket = \"gs://electric-armor-395015-netlog-bucket\"\n",
    "# Define the Cloud Dataflow pipeline\n",
    "pipeline = beam.Pipeline()\n",
    "\n",
    "# Read from PubSub and write to GCS\n",
    "(pipeline\n",
    "  | \"Read from PubSub\" >> beam.Create(list(range(50)))\n",
    "  | \"Transform data\" >> beam.Map(lambda x: x * 2)\n",
    "  | \"Write to GCS\" >> beam.Map(print))\n",
    "\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam.io.WriteToText(\"gs://electric-armor-395015-netlog-bucket/test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python src/data-pipeline/main.py --topic projects/electric-armor-395015/topics/${TOPIC_NAME} --qps 100 --anomaly True --runner TestDataFlowRunner --sdk_container_image gcr.io/electric-armor-395015/netlog-stream-template:${TAG} --project electric-armor-395015 --region europe-west2 --temp_location gs://${BUCKET}/tmp --staging_location gs://${BUCKET}/staging --job_name netlog-stream-job --max_num_workers 1 --worker_machine_type n1-standard-1 --job_name test23456789"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
